# Copilot Instructions: Modular Audio Engine

## Project Overview

This is a **React + TypeScript web application** for building and playing modular synthesizers visually. It's a node-based audio routing system similar to tools like Max/MSP or Pure Data, but browser-based using the Web Audio API.

## Core Architecture

### Three-Layer Structure

1. **UI Layer** (`src/ui/Layout/Layout.tsx`)
   - Three-panel design: left blade (tools), center workspace, right blade (inspector)
   - Three modes: "synth-editor", "ui-editor", "play-mode"
   - Drag-and-drop nodes via `@dnd-kit/core`

2. **State Management** (React Context)
   - `PatchContext`: Patch JSON state, node/connection CRUD
   - `AudioEngine`: Web Audio API wrapper
   - `MidiContext`: MIDI input state
   - Other contexts: `BladeContext`, `ModeContext`, `ConnectionEditContext`

3. **Audio Backend** (`src/audio/AudioEngine.ts`)
   - Interprets JSON patch definitions
   - Creates/manages Web Audio nodes (oscillators, gains, filters, etc.)
   - Handles MIDI input and keyboard playback
   - Builds audio graphs dynamically from patch connections

## Key Data Model

`src/model/PatchTypes.ts` defines:

- **Nodes**: `oscillator`, `gain`, `filter`, `envelope`, `destination`
- **Connections**: `audio` (signal flow) or `control` (envelope modulation)
- **Patch**: Collection of nodes + connections

Example signal flow:
```
Oscillator → Gain → Filter → Destination
              ↑
            Envelope (control)
```

## UI Components

- **Workspace**: Draggable nodes that render as SVG icons
- **ConnectionLayer**: Draws audio cables (white) and control cables (yellow dashed)
- **NodeInspector**: Right panel for editing selected node parameters (frequency, waveform, gain, filter cutoff/resonance, ADSR envelope)
- **LeftBlade**: Tools to add nodes (buttons)

## Features

✅ Build patches visually with drag-drop nodes  
✅ Real-time audio synthesis using Web Audio API  
✅ MIDI input support (keyboard mapping + MIDI devices)  
✅ Envelope modulation (ADSR control connections)  
✅ Live parameter editing (frequency, gain, filter, envelope)  
✅ Factory patches (JSON in public assets)  
✅ Local storage for user patches  
✅ Audio level visualization in footer  

## Build & Deploy

- **Vite** for dev/build
- **TypeScript** strict mode
- **Deployed to GitHub Pages** via `deploy:gh` script

## Development Tips

- Patch state mutations happen through `PatchContext` actions
- Audio node creation is triggered in `AudioEngine` when patch changes
- MIDI keyboard input flows through `MidiContext`
- Node positioning is managed by the drag-and-drop layer in Workspace

## File Structure

```
src/
  audio/
    AudioEngine.ts          # Main Web Audio API orchestrator
    AudioEngine/
      Core.ts              # Node creation/destruction
      Playback.ts          # MIDI/keyboard playback
      Setters.ts           # Parameter updates
      Adders.ts            # Audio node creation helpers
  context/                 # React Context providers
  model/
    PatchTypes.ts          # TypeScript interfaces for patch data
  ui/
    Layout/                # Main layout components
    NodeInspector.tsx      # Parameter editor panel
    Workspace/             # Node canvas and connections
```

## Audio Engine Deep Dive

### Core Components

The `AudioEngine` is a Web Audio API wrapper that converts modular patch JSON into real-time synthesizer audio.

**Audio Chain:**
```
[Web Audio Nodes] → destinationInput (GainNode) → analyser → speakers
```

- `destinationInput`: Internal gain node that all outputs route through
- `analyser`: Captures frequency data for audio level visualization (FFT size 2048)

**Node Mapping** (`webNodes: Map<string, AudioNode>`):
- Maps patch node IDs to actual Web Audio API nodes
- Types: `OscillatorNode`, `GainNode`, `BiquadFilterNode`, `destination`

### Three Main Workflows

**1. Graph Building** (`buildPatchNodes` + `connectPatch`)
- First pass: Create Web Audio nodes from patch definition
- Second pass: Connect them according to `patch.connections`
  - `audio` connections: `fromNode.connect(toNode)` (signal routing)
  - `control` connections: Apply ADSR envelopes to parameters

**2. Playing a Note** (`noteOn` / `noteOff`)
Called when user presses MIDI key or keyboard:
- Sets oscillator frequency to the note
- Starts oscillators (once per graph build)
- Applies ADSR envelopes to control parameters (gain, filter cutoff, etc.)
- Stores release callbacks in `activeReleases` map
- `noteOff()` triggers all release phases simultaneously

Envelope application:
```
Attack:   0 → 1 (over attack time)
Decay:    1 → sustain (over decay time)
Sustain:  held at sustain level
Release:  sustain → 0 (when noteOff called)
```

**3. One-Shot Playback** (`playAll`)
- Creates fresh Web Audio graph
- Plays all oscillators for fixed duration
- Used for factory patches preview

### MIDI & Keyboard Integration

- **MIDI Input**: `handleMIDIMessage` listens to MIDI devices
  - Converts MIDI note number → frequency via `midiNoteToFreq()`
  - Routes through `noteOn(activePatch, freq, velocity)`
  - Calls registered callbacks for UI updates

- **Keyboard Input**: Handled by `MidiContext` (calls `noteOn`/`noteOff`)

### Real-time Parameter Updates

Setters update both the **patch JSON** and **live Web Audio node**:
```typescript
setNodeGain(nodeId, value) {
  node.params.value = value;                      // Update JSON
  webNode.gain.setValueAtTime(value, now);        // Update audio immediately
}

setNodeFilterCutoff(nodeId, cutoff) {
  node.params = { ...node.params, cutoff };       // Update JSON
  // Web Audio node updates happen during next graph rebuild
}
```

### Safety Features

- **Panic button** (`panic()`): Stops all oscillators, zeros all gains, disconnects nodes
- **Graph caching** (`graphBuilt` flag): Prevents rebuilding on every note
- **Active releases tracking** (`activeReleases` map): Ensures clean release phases

### Audio Level Monitoring

```typescript
getAudioLevel() {
  analyser.getByteTimeDomainData(data)  // Get raw waveform
  // Compute RMS (Root Mean Square) for normalized level [0-1]
}
```
Used by the Footer to display real-time audio level visualization.

### Design Pattern

The engine keeps **two representations in sync**:
1. **Patch JSON** (the "source of truth" state)
2. **Web Audio nodes** (the live-playing audio)

This allows parameter editing during playback while maintaining audio continuity.

## NodeInspector Component

The `NodeInspector` (`src/ui/NodeInspector.tsx`) is the **right-side parameter editing panel** that allows users to adjust individual node properties in real-time.

### Architecture

**State Management Pattern:**
- Uses `usePatch()` hook to access global patch state and selected node
- Maintains **local component state** for each parameter
- Two-step workflow: **Edit locally** → **Apply to patch & audio**

### Data Flow

1. **Selection** → Node gets selected from workspace
2. **Load** → `useEffect` populates local state from selected node params
3. **Edit** → User adjusts sliders/inputs (local state only, live feedback)
4. **Apply** → Button click syncs changes to both:
   - **Patch JSON** via `setPatch()`
   - **Live Web Audio node** via `audioEngine.setNode*()`

### Node Type Editors

**Oscillator Editor**
- Frequency (number input): User-entered Hz value
- Waveform (dropdown): sine, triangle, square, sawtooth
- Apply: Calls `setNodeFrequency()` + `setNodeWaveform()`

**Gain Editor**
- Gain (range slider): 0–1 with 0.01 step precision
- Display: Decimal format (0.00–1.00)
- Apply: Calls `setNodeGain()` for immediate audio update

**Filter Editor**
- Type (dropdown): Lowpass (LP) or Highpass (HP)
- Cutoff (range slider): Uses logarithmic frequency scale
  - Maps to Hz via `sliderToFreq()` / `freqToSlider()` utilities
  - Allows smooth control from ~10 Hz to 20 kHz
- Resonance (range slider): 0.1–100 (Q factor)
- Apply: Calls `setNodeFilter()`

**Envelope (ADSR) Editor**
- Attack (0–2s): Time to peak
- Decay (0–2s): Time to sustain level
- Sustain (0–100%): Held level while note plays
- Release (0–3s): Time to silence after note off
- Apply: Calls `setEnvelopeParams()`

**Destination Editor**
- Read-only: "Represents the hardware"
- Cannot be deleted (immutable)

### Key Patterns

**Type Guarding**: Uses helper functions (`isOscillatorNode()`, `isGainNode()`, etc.) to safely access node-specific params

**Dual State Sync**: Every Apply button:
1. Updates patch JSON via `setPatch(prev => ...map nodes...)`
2. Updates live Web Audio via `audioEngine.setNode*()`

**Logarithmic Scaling**: Filter cutoff uses `sliderToFreq()` to map linear slider range to perceptually-natural Hz values

### UI Structure

```tsx
<div className="bladeRight">
  <div className="bladeHeader">Kind: [NODE TYPE]</div>
  <div className="bladeItem">
    [Label]: [Input/Slider/Select]
    <div>[Current Value Display]</div>
  </div>
  <div className="bladeButtonWrapper">
    <button>Apply</button>
    <button className="btnDelete">Delete Node</button>
  </div>
</div>
```

### Integration with PatchContext

- `patch`: Current synth state
- `selectedNodeId`: Which node is being edited
- `setPatch()`: Trigger patch update (causes `AudioEngine.rebuildPatchGraph()`)
- `deleteNode()`: Remove node from patch and connections
